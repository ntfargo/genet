{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if 'NRCH' in pe_system: # for NRCH-PE PAM\n",
    "    dict_sRE = {'+': '[ACGT][ACGT]G[ACGT]|[ACGT][CG]A[ACGT]|[ACGT][AG]CC|[ATCG]ATG', \n",
    "                '-': '[ACGT]C[ACGT][ACGT]|[ACGT]T[CG][ACGT]|G[GT]T[ACGT]|ATT[ACGT]|CAT[ACGT]|GGC[ACGT]|GTA[ACGT]'} \n",
    "else:\n",
    "    dict_sRE = {'+': '[ACGT]GG[ACGT]', '-': '[ACGT]CC[ACGT]'} # for Original-PE PAM\n",
    "\n",
    "for sStrand in ['+', '-']:\n",
    "\n",
    "    sRE = dict_sRE[sStrand]\n",
    "'''\n",
    "\n",
    "import regex\n",
    "import pandas as pd\n",
    "from genet.models import LoadModel\n",
    "\n",
    "\n",
    "def reverse_complement(sSeq):\n",
    "    dict_sBases = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N', 'U': 'U', 'n': '',\n",
    "                   '.': '.', '*': '*', 'a': 't', 'c': 'g', 'g': 'c', 't': 'a'}\n",
    "    list_sSeq = list(sSeq)  # Turns the sequence in to a gigantic list\n",
    "    list_sSeq = [dict_sBases[sBase] for sBase in list_sSeq]\n",
    "    return ''.join(list_sSeq)[::-1]\n",
    "\n",
    "# def END: reverse_complement\n",
    "\n",
    "model = LoadModel('DeepSpCas9', 'SpCas9')\n",
    "\n",
    "'''\n",
    "dict_pattern = {\n",
    "    '+': '[ATGC]{25}GG[ATGC]{3}',\n",
    "    '-': '[ATGC]{3}CC[ATGC]{25}',\n",
    "}\n",
    "'''\n",
    "\n",
    "dict_re = model.info['regex']\n",
    "\n",
    "seq_input = 'ctctacgtctcctccgagagccgcttcaacaccctggccgagttggttcatcatcattcaacggtggccgacgggctcatcaccacgctccattatccagccccaaagcgcaacaagcccactgtctatggtgtgtcccccaactacgacaagtgggagatggaacgcacggacatcaccatgaagcacaagctgggcgggggccagtacggggaggtgtacgagggcgtgtggaagaaatacagcctgacggtggccgtgaagaccttgaag'\n",
    "seq_input = seq_input.upper()\n",
    "\n",
    "seq_target, seq_guide, seq_strand, pos_start, pos_end = [], [], [], [], []\n",
    "\n",
    "for strand in ['+', '-']:\n",
    "    ptn = dict_re[strand]\n",
    "\n",
    "    for re_idx in regex.finditer(ptn, seq_input, overlapped=True):\n",
    "        \n",
    "        if strand == '+': match = re_idx.group()\n",
    "        else            : match = reverse_complement(re_idx.group())\n",
    "        \n",
    "        seq_target.append(match)\n",
    "        seq_guide.append(match[4:24])\n",
    "        seq_strand.append(strand)\n",
    "        pos_start.append(re_idx.start())\n",
    "        pos_end.append(re_idx.end())\n",
    "        \n",
    "\n",
    "df_out = pd.DataFrame({'Target': seq_target,\n",
    "                       'Spacer': seq_guide,\n",
    "                       'Strand': seq_strand,\n",
    "                       'Start': pos_start,\n",
    "                       'End': pos_end})\n",
    "\n",
    "df_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class LogStreamHandler(logging.StreamHandler):\n",
    "    def __init__(self, stream=None):\n",
    "        super().__init__(stream)\n",
    "        self.setFormatter(logging.Formatter(\n",
    "            '%(levelname)-5s @ %(asctime)s:\\n\\t %(message)s \\n',\n",
    "            datefmt='%a, %d %b %Y %H:%M:%S',\n",
    "        ))\n",
    "        self.setLevel(logging.INFO)\n",
    "\n",
    "class StatusFormatter(logging.Formatter):\n",
    "    def format(self, record):\n",
    "        record.percent_complete = ''\n",
    "        if record.args and 'percent_complete' in record.args:\n",
    "            record.percent_complete = '{0:.2f}% '.format(record.args['percent_complete'])\n",
    "            self.last_percent_complete = record.percent_complete\n",
    "        elif hasattr(self, 'last_percent_complete'): # if we don't have a percent complete, use the last one\n",
    "            record.percent_complete = self.last_percent_complete\n",
    "        return super().format(record)\n",
    "\n",
    "class StatusHandler(logging.FileHandler):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__(filename, 'w')\n",
    "        self.setFormatter(StatusFormatter('%(percent_complete)s%(message)s'))\n",
    "\n",
    "    def emit(self, record):\n",
    "        \"\"\"Overwrite the existing file and write the new log.\"\"\"\n",
    "        if self.stream is None:  # log file is empty\n",
    "            self.stream = self._open()\n",
    "        else:  # log file is not empty, overwrite\n",
    "            self.stream.seek(0)\n",
    "        logging.StreamHandler.emit(self, record)\n",
    "        self.stream.truncate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os, sys\n",
    "import genet\n",
    "\n",
    "class DeepPrime:\n",
    "    '''\n",
    "    DeepPrime: pegRNA activity prediction models\\n\n",
    "    Input  = 121 nt DNA sequence without edit\\n\n",
    "    Output = 121 nt DNA sequence with edit\\n\n",
    "    \n",
    "    ### Available Edit types\\n\n",
    "    sub1, sub2, sub3, ins1, ins2, ins3, del1, del2, del3\\n\n",
    "    \n",
    "    ### Available PE systems\\n\n",
    "    PE2, PE2max, PE4max, NRCH_PE2, NRCH_PE2max, NRCH_PE4max\\n\n",
    "    \n",
    "    ### Available Cell types\\n\n",
    "    HEK293T, HCT116, MDA-MB-231, HeLa, DLD1, A549, NIH3T3\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, sID:str, Ref_seq: str, ED_seq: str, edit_type: str, edit_len: int,\n",
    "                pam:str = 'NGG', pbs_min:int = 7, pbs_max:int = 15,\n",
    "                rtt_min:int = 0, rtt_max:int = 40, silence:bool = False,\n",
    "                out_dir:str=os.getcwd(),\n",
    "                ):\n",
    "        \n",
    "        # input parameters\n",
    "        self.nAltIndex = 60\n",
    "        self.sID, self.Ref_seq, self.ED_seq = sID, Ref_seq, ED_seq\n",
    "        self.edit_type, self.edit_len, self.pam = edit_type, edit_len, pam\n",
    "        self.pbs_min, self.pbs_max = pbs_min, pbs_max\n",
    "        self.pbs_range = [pbs_min, pbs_max]\n",
    "        self.rtt_min, self.rtt_max   = rtt_min, rtt_max\n",
    "        self.silence = silence\n",
    "        \n",
    "        # output directory\n",
    "        self.OUT_PATH = '%s/%s/'  % (out_dir, self.sID)\n",
    "        self.TEMP_DIR = '%s/temp' % self.OUT_PATH\n",
    "        \n",
    "        # initializing\n",
    "        self.set_logging()\n",
    "        self.check_input()\n",
    "\n",
    "        ## FeatureExtraction Class\n",
    "        cFeat = FeatureExtraction()\n",
    "\n",
    "        cFeat.input_id = sID\n",
    "        cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)\n",
    "\n",
    "        cFeat.get_sAltNotation(nAltIndex)\n",
    "        cFeat.get_all_RT_PBS(nAltIndex, nMinPBS=pbs_range[0]-1, nMaxPBS=pbs_range[1], nMaxRT=rtt_max, pe_system=pe_system)\n",
    "        cFeat.make_rt_pbs_combinations()\n",
    "        cFeat.determine_seqs()\n",
    "        cFeat.determine_secondary_structure()\n",
    "\n",
    "        self.features = cFeat.make_output_df()\n",
    "        \n",
    "        del cFeat\n",
    "\n",
    "\n",
    "        self.logger.info('Created an instance of DeepPrime')\n",
    "\n",
    "    # def __init__: END\n",
    "\n",
    "\n",
    "    def submit(self, pe_system:str, cell_type:str = 'HEK293T'):\n",
    "        print('start pe_scre', self.Ref_seq, self.ED_seq, )\n",
    "\n",
    "        return None\n",
    "\n",
    "    # def submit: END\n",
    "\n",
    "\n",
    "    def set_logging(self):\n",
    "\n",
    "        self.logger = logging.getLogger(self.OUT_PATH)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "        self.formatter = logging.Formatter(\n",
    "            '%(levelname)-5s @ %(asctime)s:\\n\\t %(message)s \\n',\n",
    "            datefmt='%a, %d %b %Y %H:%M:%S',\n",
    "            )\n",
    "        \n",
    "        self.error = self.logger.error\n",
    "        self.warn  = self.logger.warn\n",
    "        self.debug = self.logger.debug\n",
    "        self.info  = self.logger.info\n",
    "\n",
    "        try:\n",
    "            os.makedirs(self.OUT_PATH, exist_ok=True)\n",
    "            os.makedirs(self.TEMP_DIR, exist_ok=True)\n",
    "            self.info('Creating Folder %s' % self.OUT_PATH)\n",
    "        except:\n",
    "            self.error('Creating Folder failed')\n",
    "            sys.exit(1)\n",
    "            \n",
    "        self.file_handler = logging.FileHandler('%s/log_%s.log' % (self.OUT_PATH, self.sID))\n",
    "        self.file_handler.setLevel(logging.DEBUG)\n",
    "        self.file_handler.setFormatter(self.formatter)\n",
    "        self.logger.addHandler(self.file_handler)\n",
    "        \n",
    "        if self.silence != True:\n",
    "            self.console_handler = logging.StreamHandler()\n",
    "            self.console_handler.setLevel(logging.DEBUG)\n",
    "            self.console_handler.setFormatter(self.formatter)\n",
    "            self.logger.addHandler(self.console_handler)\n",
    "\n",
    "        self.info('DeepPrime: pegRNA activity prediction models\\n\\t version: %s' % genet.__version__)\n",
    "\n",
    "\n",
    "        return None\n",
    "\n",
    "    # def set_logging: END\n",
    "\n",
    "\n",
    "    def check_input(self):\n",
    "        \n",
    "        if self.pbs_min < 1:\n",
    "            self.error('sID:%s\\nPlease set PBS max length at least 1nt' % self.sID)\n",
    "            raise ValueError('Please check your input: pbs_min')\n",
    "        \n",
    "        if self.pbs_max > 17:\n",
    "            self.error('sID:%s\\nPlease set PBS max length upto 17nt' % self.sID)\n",
    "            raise ValueError('Please check your input: pbs_max')\n",
    "        \n",
    "        if self.rtt_max > 40:\n",
    "            self.error('sID:%s\\nPlease set RTT max length upto 40nt' % self.sID)\n",
    "            raise ValueError('Please check your input: rtt_max')\n",
    "\n",
    "        if self.edit_type not in ['sub', 'ins', 'del']:\n",
    "            self.error('sID:%s\\n\\t Please select proper edit type.\\n\\t Available edit tyle: sub, ins, del' % self.sID)\n",
    "            raise ValueError('Please check your input: edit_type')\n",
    "\n",
    "        if self.edit_len > 3:\n",
    "            self.error('sID:%s\\n\\t Please set edit length upto 3nt. Available edit length range: 1~3nt' % self.sID)\n",
    "            raise ValueError('Please check your input: edit_len')\n",
    "        \n",
    "        if self.edit_len < 1:\n",
    "            self.error('sID:%s\\n\\t Please set edit length at least 1nt. Available edit length range: 1~3nt' % self.sID)\n",
    "            raise ValueError('Please check your input: edit_len')\n",
    "\n",
    "        self.info('Input information\\n\\t ID: %s\\n\\t Refseq: %s\\n\\t EDseq :%s' % (self.sID, self.Ref_seq, self.ED_seq))\n",
    "\n",
    "        return None\n",
    "    \n",
    "    # def check_input: END\n",
    "\n",
    "\n",
    "    def do_something(self):\n",
    "        self.logger.info('Something happened.')\n",
    "\n",
    "        return None\n",
    "\n",
    "    # def do_something: END\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_a = DeepPrime(sID='Sample_1',\n",
    "                  Ref_seq='ATGACAATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGAAGAACTATAACCTGCAAATGTCAACTGAAACCTTAAAGTGAGTATTTAATTGAGCTGAAGT', \n",
    "                  ED_seq='ATGACAATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGAACTATAACCTGCAAATGTCAACTGAAACCTTAAAGTGAGTATTTAATTGAGCTGAAGT',\n",
    "                  edit_type='sub',\n",
    "                  edit_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_a.do_something()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_b = DeepPrime(sID='Sample_2',\n",
    "                  Ref_seq='ATGACAATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGAAGAACTATAACCTGCAAATGTCAACTGAAACCTTAAAGTGAGTATTTAATTGAGCTGAAGT', \n",
    "                  ED_seq='ATGACAATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGAACTATAACCTGCAAATGTCAACTGAAACCTTAAAGTGAGTATTTAATTGAGCTGAAGT',\n",
    "                  edit_type='sub',\n",
    "                  edit_len=1,\n",
    "                  silence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, logging\n",
    "\n",
    "\n",
    "logger = logging.getLogger('example')\n",
    "\n",
    "\n",
    "raise ValueError('Error!@@!@!@')\n",
    "\n",
    "logger.error('Error')\n",
    "\n",
    "\n",
    "\n",
    "print('Error occured')\n",
    "sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81e374b3269ecf0079033d8d54c3b8445e57606735e601277613154e83e18b39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
